# ğŸš€ RaGME_UP - PROP

SystÃ¨me RAG (Retrieval-Augmented Generation) pour l'indexation et l'interrogation de documents techniques avec FAISS, Snowflake Arctic Embeddings et DALLEM. Inclut un systÃ¨me de feedback utilisateur avec re-ranking intelligent.

---

## ğŸ“– Documentation

- **[Guide Utilisateur](GUIDE_UTILISATEUR.md)** - Documentation complÃ¨te pour utiliser l'application
- **[Installation RÃ©seau](INSTALLATION_RESEAU.md)** - Guide de dÃ©ploiement multi-utilisateurs
- **[Architecture Technique](ARCHITECTURE_TECHNIQUE.md)** - Documentation technique complÃ¨te (chunking, parsers, pipeline)

---

## âš¡ DÃ©marrage rapide

### Installation

```bash
# Windows: double-cliquez sur
install.bat
```

### Lancement

```bash
# Windows: double-cliquez sur
launch.bat

# Ou manuellement
streamlit run streamlit_RAG.py
```

L'application s'ouvre automatiquement dans votre navigateur sur `http://localhost:8501`

---

## âœ¨ FonctionnalitÃ©s principales

- ğŸ“ **Gestion CSV** avec interface GUI moderne
- ğŸ“¥ **Ingestion documents** (PDF, DOCX, TXT) avec tracking automatique
- ğŸ”’ **Coordination multi-utilisateurs** avec systÃ¨me de verrous
- ğŸ—‘ï¸ **Purge des bases** FAISS
- â“ **Questions RAG** avec recherche sÃ©mantique et gÃ©nÃ©ration de rÃ©ponses
- ğŸ“ **Feedback utilisateur** : Ã©valuation granulaire des rÃ©ponses et sources
- ğŸ”„ **Re-ranking intelligent** : amÃ©lioration des rÃ©sultats basÃ©e sur les feedbacks
- ğŸ“Š **Tableau de bord analytique** : statistiques et tendances des retours
- ğŸ‘¥ **Authentification** utilisateurs pour l'accÃ¨s aux paramÃ¨tres

---

## ğŸ§© SystÃ¨me de Chunking AvancÃ©

Le systÃ¨me RAG utilise un **chunking adaptatif intelligent** qui s'adapte automatiquement au type de document et Ã  la densitÃ© du contenu.

### DÃ©tection automatique du type de document

| Type de document | DÃ©tection | StratÃ©gie appliquÃ©e |
|------------------|-----------|---------------------|
| **Documents EASA** | Headers `CS 25.xxx`, `AMC`, `GM` | Chunking par sections rÃ©glementaires |
| **Documents gÃ©nÃ©riques** | Tout autre document | Smart chunking avec prÃ©servation de structure |

### Techniques de chunking implÃ©mentÃ©es

#### 1. ğŸ“Š Analyse de densitÃ© du contenu

Le systÃ¨me analyse automatiquement chaque document pour dÃ©tecter sa densitÃ© :

| DensitÃ© | CaractÃ©ristiques | Taille chunk |
|---------|------------------|--------------|
| **very_dense** | Code, formules, tableaux, nombreuses rÃ©fÃ©rences | 800 chars |
| **dense** | Texte technique, spÃ©cifications, listes | 1200 chars |
| **normal** | Texte standard, prose technique | 1500 chars |
| **sparse** | Narratif, introductions, descriptions | 2000 chars |

**MÃ©triques analysÃ©es :**
- DensitÃ© de termes techniques (80+ mots-clÃ©s aÃ©ronautiques)
- Ratio nombres/formules
- Longueur moyenne des phrases
- PrÃ©sence de listes et tableaux
- DensitÃ© de rÃ©fÃ©rences (CS, AMC, GM, FAR, JAR)
- Ratio d'acronymes

#### 2. âœˆï¸ Chunking EASA spÃ©cialisÃ©

Pour les documents rÃ©glementaires EASA (CS-25, CS-E, etc.) :

```
[CS 25.571 - Damage tolerance and fatigue evaluation of structure]
The evaluation... (contenu de la section)
```

**FonctionnalitÃ©s :**
- DÃ©tection des sections par regex : `CS`, `AMC`, `GM`, `CS-E`, `CS-APU`
- PrÃ©servation du contexte `[Section ID - Title]` dans chaque chunk
- DÃ©coupage intelligent par sous-paragraphes `(a)`, `(b)`, `(1)`, `(2)`
- Fusion automatique des petites sections (<300 chars)
- Pas de redÃ©coupage des sections dÃ©jÃ  petites

#### 3. ğŸ“„ Smart chunking gÃ©nÃ©rique

Pour les documents non-EASA :

- **PrÃ©servation des headers** : Les titres restent avec leur contenu
- **PrÃ©servation des listes** : Ne coupe jamais au milieu d'une liste
- **Coupure aux phrases** : Respecte les fins de phrases
- **Contexte source** : Ajoute `[Source: filename]` pour traÃ§abilitÃ©
- **Overlap configurable** : Chevauchement pour garder le contexte

#### 4. ğŸ·ï¸ Augmentation des chunks

Chaque chunk est enrichi avec des mÃ©tadonnÃ©es pour amÃ©liorer la recherche :

```python
{
    "text": "...",                    # Contenu du chunk
    "keywords": ["fatigue", "CS 25.571", "structure"],  # Mots-clÃ©s extraits
    "key_phrases": ["shall be evaluated..."],           # Phrases clÃ©s (exigences)
    "density_type": "dense",          # Type de densitÃ©
    "density_score": 0.45,            # Score de densitÃ©
    "references_to": ["CS 25.573", "AMC 25.571"]       # RÃ©fÃ©rences dÃ©tectÃ©es
}
```

**Extraction de mots-clÃ©s :**
- Filtrage des stopwords (FR + EN)
- Bonus pour termes techniques aÃ©ronautiques
- Extraction des codes de rÃ©fÃ©rence (CS, AMC, GM)

#### 5. ğŸ”— DÃ©tection des rÃ©fÃ©rences croisÃ©es

Le systÃ¨me dÃ©tecte automatiquement les liens entre sections :

**Patterns dÃ©tectÃ©s :**
- RÃ©fÃ©rences directes : `CS 25.571`, `AMC 25.1309`, `GM 25.631`
- RÃ©fÃ©rences contextuelles : `see CS 25.571`, `refer to AMC...`, `in accordance with...`
- RÃ©fÃ©rences FAR/JAR : `FAR 25.571`, `JAR 25.571`
- RÃ©fÃ©rences internes : `paragraph (a)`, `sub-paragraph (1)`

**Stockage :**
```python
chunk["references_to"] = ["CS 25.573", "AMC 25.571"]  # Max 5 rÃ©fÃ©rences
```

#### 6. ğŸ” Expansion de contexte (Query-Time)

Lors de la recherche, le systÃ¨me enrichit automatiquement les rÃ©sultats :

| FonctionnalitÃ© | Description |
|----------------|-------------|
| **Chunks voisins** | Ajoute les chunks prÃ©cÃ©dent/suivant du mÃªme fichier |
| **Chunks rÃ©fÃ©rencÃ©s** | Si un chunk mentionne `CS 25.573`, inclut les chunks de cette section |
| **Index inversÃ©** | Lookup rapide des chunks par rÃ©fÃ©rence |

**Activation :** `use_context_expansion=True` (par dÃ©faut)

### Architecture du chunking

```
Document
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DÃ©tection type document    â”‚
â”‚  (EASA vs GÃ©nÃ©rique)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
    â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EASA Parser â”‚    â”‚ Smart Chunk â”‚
â”‚ (sections)  â”‚    â”‚ (generic)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analyse densitÃ© contenu    â”‚
â”‚  â†’ Adaptation taille chunks â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Augmentation chunks     â”‚
â”‚  (keywords, key_phrases)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DÃ©tection cross-rÃ©fÃ©rences â”‚
â”‚  (CS, AMC, GM, FAR, JAR)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        Chunks indexÃ©s
```

### Fichiers concernÃ©s

| Fichier | RÃ´le |
|---------|------|
| `chunking.py` | Toutes les fonctions de chunking et augmentation |
| `easa_sections.py` | Parser de sections EASA (CS/AMC/GM) |
| `rag_ingestion.py` | Orchestration du chunking lors de l'ingestion |
| `rag_query.py` | Context expansion lors des requÃªtes |

---

## ğŸ“„ SystÃ¨me de Parsing Multi-Format

Le systÃ¨me supporte l'extraction de texte depuis de multiples formats de documents avec des stratÃ©gies de fallback robustes.

### Formats supportÃ©s

| Format | BibliothÃ¨que principale | Fallback | FonctionnalitÃ©s spÃ©ciales |
|--------|------------------------|----------|---------------------------|
| **PDF** | pdfplumber | pdfminer.six â†’ PyMuPDF | **Extraction tableaux**, piÃ¨ces jointes, nettoyage Unicode |
| **DOCX** | python-docx | - | Tables, sections, paragraphes |
| **DOC** | - | - | âš ï¸ Non supportÃ© (convertir en .docx) |
| **XML** | xml.etree.ElementTree | - | Patterns EASA configurables |
| **TXT/MD** | Lecture native | - | DÃ©tection encodage |
| **CSV** | Lecture native | - | Extraction texte brut |

### Parser PDF (`pdf_processing.py`)

Le parser PDF est le plus sophistiquÃ© avec une architecture Ã  triple fallback et extraction de tableaux :

```
PDF Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pdfplumber             â”‚  â† Extraction principale (tableaux)
â”‚  (texte + tableaux)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Ã‰chec ou texte suspect?
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pdfminer.six           â”‚  â† Fallback 1
â”‚  (extraction texte)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Ã‰chec ou texte suspect?
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PyMuPDF (fitz)         â”‚  â† Fallback 2 robuste
â”‚  (extraction fallback)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extraction piÃ¨ces      â”‚  â† Automatique
â”‚  jointes rÃ©cursive      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Nettoyage Unicode      â”‚  â† Surrogates, encodages
â”‚  & caractÃ¨res spÃ©ciaux  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FonctionnalitÃ©s clÃ©s :**
- **Extraction tableaux** : pdfplumber dÃ©tecte et formate les tableaux en markdown
- **Extraction piÃ¨ces jointes** : DÃ©tecte et extrait rÃ©cursivement les PDF/fichiers attachÃ©s
- **Gestion Unicode** : Nettoyage automatique des caractÃ¨res surrogates
- **Multi-encodage** : DÃ©tection automatique (UTF-8, UTF-16, Latin-1, ISO-8859-1, CP1252)
- **Heuristiques qualitÃ©** : DÃ©tecte si l'extraction est fiable

### Parser DOCX (`docx_processing.py`)

Extraction structurÃ©e des documents Word :

```python
# Modes d'extraction disponibles
docx_to_text(path)                    # Texte complet
extract_paragraphs_from_docx(path)    # Liste des paragraphes
extract_sections_from_docx(path)      # Sections par headers (Heading 1/2)
extract_text_from_tables(path)        # Contenu des tableaux
```

**FonctionnalitÃ©s :**
- PrÃ©servation des sauts de ligne
- DÃ©tection des styles de titres (Heading 1/2, Titre 1/2)
- Extraction des tableaux
- Normalisation des espaces

### Parser XML EASA (`xml_processing.py`)

Parser configurable pour les documents XML rÃ©glementaires :

```python
# Patterns prÃ©configurÃ©s
class SectionPattern(Enum):
    CS_STANDARD = r"CS[-\s]?25[.\s]?\d+"      # CS 25.101, CS-25.101
    AMC = r"AMC[-\s]?25[.\s]?\d+"              # AMC 25.101
    GM = r"GM[-\s]?25[.\s]?\d+"                # GM 25.101
    CS_E = r"CS[-\s]?E[-\s]?\d+"               # CS-E 100
    CS_APU = r"CS[-\s]?APU[-\s]?\d+"           # CS-APU 100
    ALL_EASA = r"(CS|AMC|GM)[-\s]?..."         # Tous patterns
    CUSTOM = "custom"                          # Pattern personnalisÃ©
```

**Configuration :**
```python
XMLParseConfig(
    pattern_type=SectionPattern.ALL_EASA,
    custom_pattern=None,           # Pour pattern personnalisÃ©
    include_section_title=True,
    min_section_length=50,
    excluded_tags=['note', 'amendment']
)
```

### Chargement unifiÃ© (`rag_ingestion.py`)

Le systÃ¨me dÃ©tecte automatiquement le format et applique le parser appropriÃ© :

```python
def load_file_content(path, xml_configs=None):
    extension = Path(path).suffix.lower()

    if extension == '.pdf':
        return extract_text_and_attachments(path)
    elif extension in ['.docx', '.doc']:
        return docx_to_text(path)
    elif extension == '.xml':
        return parse_xml_with_config(path, xml_configs)
    elif extension in ['.txt', '.md']:
        return read_text_file(path)
    elif extension == '.csv':
        return extract_csv_text(path)
```

**Traitement parallÃ¨le :**
- ThreadPoolExecutor pour compatibilitÃ© Windows
- Nombre de workers = CPU count
- Gestion robuste des erreurs par fichier

---

## âš™ï¸ Configuration des rÃ©pertoires

L'application nÃ©cessite plusieurs rÃ©pertoires de stockage. Au premier lancement, si ces rÃ©pertoires ne sont pas accessibles, une **page de configuration** s'affiche automatiquement.

### RÃ©pertoires requis

| RÃ©pertoire | Description |
|------------|-------------|
| **Bases FAISS** | Stockage des index vectoriels FAISS |
| **CSV ingestion** | Fichiers CSV pour l'ingestion de documents |
| **CSV tracking** | Fichiers de suivi des documents ingÃ©rÃ©s |
| **Feedbacks** | Stockage des feedbacks utilisateurs |

### Configuration automatique

1. Au lancement, l'application vÃ©rifie l'accessibilitÃ© de tous les rÃ©pertoires
2. Si un rÃ©pertoire est manquant ou inaccessible :
   - Une page de configuration s'affiche
   - Vous pouvez **crÃ©er les rÃ©pertoires manquants** automatiquement
   - Ou **modifier les chemins** selon votre environnement
3. La configuration est sauvegardÃ©e dans `config.json` (fichier local, ignorÃ© par git)

### Fichier de configuration

```json
{
  "base_root_dir": "C:\\Data\\FAISS_DATABASE\\BaseDB",
  "csv_import_dir": "C:\\Data\\FAISS_DATABASE\\CSV_Ingestion",
  "csv_export_dir": "C:\\Data\\FAISS_DATABASE\\CSV_Tracking",
  "feedback_dir": "C:\\Data\\FAISS_DATABASE\\Feedbacks"
}
```

---

## ğŸ”§ ParamÃ¨tres de Chunking

Les paramÃ¨tres de chunking peuvent Ãªtre ajustÃ©s dans `chunking.py` et `rag_ingestion.py` :

### ParamÃ¨tres par dÃ©faut

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `base_chunk_size` | 1000 | Taille de base avant adaptation Ã  la densitÃ© |
| `min_chunk_size` | 200 | Taille minimale (fusion si infÃ©rieur) |
| `max_chunk_size` | 2000-2500 | Taille maximale aprÃ¨s adaptation |
| `overlap` | 100 | Chevauchement entre chunks consÃ©cutifs |
| `merge_small_sections` | True | Fusion des sections < 300 caractÃ¨res |

### Tailles adaptatives par densitÃ©

```python
CHUNK_SIZES = {
    "very_dense": 800,   # Code, formules, tableaux techniques
    "dense": 1200,       # SpÃ©cifications, listes de requirements
    "normal": 1500,      # Prose technique standard
    "sparse": 2000       # Narratif, introductions
}
```

### Personnalisation

Pour modifier le comportement par dÃ©faut, Ã©ditez `rag_ingestion.py` :

```python
# Ligne ~180
adapted_chunk_size = _get_adaptive_chunk_size(
    text,
    base_size=1000,      # Modifier ici
    min_size=600,        # Modifier ici
    max_size=2000        # Modifier ici
)
```

---

## ğŸ“‹ PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Windows 10/11 (ou Linux/macOS avec adaptations)
- AccÃ¨s rÃ©seau aux APIs : Snowflake (embeddings), DALLEM (LLM), BGE Reranker

---

## ğŸ†˜ Support

Consultez la documentation pour toute question :
- Questions d'utilisation â†’ [Guide Utilisateur](GUIDE_UTILISATEUR.md)
- Installation rÃ©seau â†’ [Installation RÃ©seau](INSTALLATION_RESEAU.md)
- DÃ©veloppement/maintenance â†’ [Architecture Technique](ARCHITECTURE_TECHNIQUE.md)

---

**Version:** 1.4
**DerniÃ¨re mise Ã  jour:** 2025-11-27
